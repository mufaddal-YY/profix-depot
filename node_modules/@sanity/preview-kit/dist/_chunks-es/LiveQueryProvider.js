import { jsxs, jsx, Fragment } from "react/jsx-runtime";
import { applySourceDocuments } from "@sanity/client/csm";
import { applyPatch } from "mendoza";
import { useState, useEffect, useCallback, startTransition, useMemo } from "react";
import { defineStoreContext, useRevalidate } from "./hooks.js";
import { createNode, createNodeMachine } from "@sanity/comlink";
import { createCompatibilityActors } from "@sanity/presentation-comlink";
var s = { 0: 8203, 1: 8204, 2: 8205, 3: 8290, 4: 8291, 5: 8288, 6: 65279, 7: 8289, 8: 119155, 9: 119156, a: 119157, b: 119158, c: 119159, d: 119160, e: 119161, f: 119162 }, c = { 0: 8203, 1: 8204, 2: 8205, 3: 65279 };
new Array(4).fill(String.fromCodePoint(c[0])).join("");
Object.fromEntries(Object.entries(c).map((t) => t.reverse()));
Object.fromEntries(Object.entries(s).map((t) => t.reverse()));
var S = `${Object.values(s).map((t) => `\\u{${t.toString(16)}}`).join("")}`, f = new RegExp(`[${S}]{4,}`, "gu");
function _(t) {
  var e;
  return { cleaned: t.replace(f, ""), encoded: ((e = t.match(f)) == null ? void 0 : e[0]) || "" };
}
const perf = typeof performance == "object" && performance && typeof performance.now == "function" ? performance : Date, warned = /* @__PURE__ */ new Set(), PROCESS = typeof process == "object" && process ? process : {}, emitWarning = (msg, type, code, fn) => {
  typeof PROCESS.emitWarning == "function" ? PROCESS.emitWarning(msg, type, code, fn) : console.error(`[${code}] ${type}: ${msg}`);
};
let AC = globalThis.AbortController, AS = globalThis.AbortSignal;
if (typeof AC > "u") {
  AS = class {
    onabort;
    _onabort = [];
    reason;
    aborted = !1;
    addEventListener(_2, fn) {
      this._onabort.push(fn);
    }
  }, AC = class {
    constructor() {
      warnACPolyfill();
    }
    signal = new AS();
    abort(reason) {
      if (!this.signal.aborted) {
        this.signal.reason = reason, this.signal.aborted = !0;
        for (const fn of this.signal._onabort)
          fn(reason);
        this.signal.onabort?.(reason);
      }
    }
  };
  let printACPolyfillWarning = PROCESS.env?.LRU_CACHE_IGNORE_AC_WARNING !== "1";
  const warnACPolyfill = () => {
    printACPolyfillWarning && (printACPolyfillWarning = !1, emitWarning("AbortController is not defined. If using lru-cache in node 14, load an AbortController polyfill from the `node-abort-controller` package. A minimal polyfill is provided for use by LRUCache.fetch(), but it should not be relied upon in other contexts (eg, passing it to other APIs that use AbortController/AbortSignal might have undesirable effects). You may disable this with LRU_CACHE_IGNORE_AC_WARNING=1 in the env.", "NO_ABORT_CONTROLLER", "ENOTSUP", warnACPolyfill));
  };
}
const shouldWarn = (code) => !warned.has(code), isPosInt = (n) => n && n === Math.floor(n) && n > 0 && isFinite(n), getUintArray = (max) => isPosInt(max) ? max <= Math.pow(2, 8) ? Uint8Array : max <= Math.pow(2, 16) ? Uint16Array : max <= Math.pow(2, 32) ? Uint32Array : max <= Number.MAX_SAFE_INTEGER ? ZeroArray : null : null;
class ZeroArray extends Array {
  constructor(size) {
    super(size), this.fill(0);
  }
}
class Stack {
  heap;
  length;
  // private constructor
  static #constructing = !1;
  static create(max) {
    const HeapCls = getUintArray(max);
    if (!HeapCls)
      return [];
    Stack.#constructing = !0;
    const s2 = new Stack(max, HeapCls);
    return Stack.#constructing = !1, s2;
  }
  constructor(max, HeapCls) {
    if (!Stack.#constructing)
      throw new TypeError("instantiate Stack using Stack.create(n)");
    this.heap = new HeapCls(max), this.length = 0;
  }
  push(n) {
    this.heap[this.length++] = n;
  }
  pop() {
    return this.heap[--this.length];
  }
}
class LRUCache {
  // options that cannot be changed without disaster
  #max;
  #maxSize;
  #dispose;
  #disposeAfter;
  #fetchMethod;
  #memoMethod;
  /**
   * {@link LRUCache.OptionsBase.ttl}
   */
  ttl;
  /**
   * {@link LRUCache.OptionsBase.ttlResolution}
   */
  ttlResolution;
  /**
   * {@link LRUCache.OptionsBase.ttlAutopurge}
   */
  ttlAutopurge;
  /**
   * {@link LRUCache.OptionsBase.updateAgeOnGet}
   */
  updateAgeOnGet;
  /**
   * {@link LRUCache.OptionsBase.updateAgeOnHas}
   */
  updateAgeOnHas;
  /**
   * {@link LRUCache.OptionsBase.allowStale}
   */
  allowStale;
  /**
   * {@link LRUCache.OptionsBase.noDisposeOnSet}
   */
  noDisposeOnSet;
  /**
   * {@link LRUCache.OptionsBase.noUpdateTTL}
   */
  noUpdateTTL;
  /**
   * {@link LRUCache.OptionsBase.maxEntrySize}
   */
  maxEntrySize;
  /**
   * {@link LRUCache.OptionsBase.sizeCalculation}
   */
  sizeCalculation;
  /**
   * {@link LRUCache.OptionsBase.noDeleteOnFetchRejection}
   */
  noDeleteOnFetchRejection;
  /**
   * {@link LRUCache.OptionsBase.noDeleteOnStaleGet}
   */
  noDeleteOnStaleGet;
  /**
   * {@link LRUCache.OptionsBase.allowStaleOnFetchAbort}
   */
  allowStaleOnFetchAbort;
  /**
   * {@link LRUCache.OptionsBase.allowStaleOnFetchRejection}
   */
  allowStaleOnFetchRejection;
  /**
   * {@link LRUCache.OptionsBase.ignoreFetchAbort}
   */
  ignoreFetchAbort;
  // computed properties
  #size;
  #calculatedSize;
  #keyMap;
  #keyList;
  #valList;
  #next;
  #prev;
  #head;
  #tail;
  #free;
  #disposed;
  #sizes;
  #starts;
  #ttls;
  #hasDispose;
  #hasFetchMethod;
  #hasDisposeAfter;
  /**
   * Do not call this method unless you need to inspect the
   * inner workings of the cache.  If anything returned by this
   * object is modified in any way, strange breakage may occur.
   *
   * These fields are private for a reason!
   *
   * @internal
   */
  static unsafeExposeInternals(c2) {
    return {
      // properties
      starts: c2.#starts,
      ttls: c2.#ttls,
      sizes: c2.#sizes,
      keyMap: c2.#keyMap,
      keyList: c2.#keyList,
      valList: c2.#valList,
      next: c2.#next,
      prev: c2.#prev,
      get head() {
        return c2.#head;
      },
      get tail() {
        return c2.#tail;
      },
      free: c2.#free,
      // methods
      isBackgroundFetch: (p) => c2.#isBackgroundFetch(p),
      backgroundFetch: (k, index, options, context) => c2.#backgroundFetch(k, index, options, context),
      moveToTail: (index) => c2.#moveToTail(index),
      indexes: (options) => c2.#indexes(options),
      rindexes: (options) => c2.#rindexes(options),
      isStale: (index) => c2.#isStale(index)
    };
  }
  // Protected read-only members
  /**
   * {@link LRUCache.OptionsBase.max} (read-only)
   */
  get max() {
    return this.#max;
  }
  /**
   * {@link LRUCache.OptionsBase.maxSize} (read-only)
   */
  get maxSize() {
    return this.#maxSize;
  }
  /**
   * The total computed size of items in the cache (read-only)
   */
  get calculatedSize() {
    return this.#calculatedSize;
  }
  /**
   * The number of items stored in the cache (read-only)
   */
  get size() {
    return this.#size;
  }
  /**
   * {@link LRUCache.OptionsBase.fetchMethod} (read-only)
   */
  get fetchMethod() {
    return this.#fetchMethod;
  }
  get memoMethod() {
    return this.#memoMethod;
  }
  /**
   * {@link LRUCache.OptionsBase.dispose} (read-only)
   */
  get dispose() {
    return this.#dispose;
  }
  /**
   * {@link LRUCache.OptionsBase.disposeAfter} (read-only)
   */
  get disposeAfter() {
    return this.#disposeAfter;
  }
  constructor(options) {
    const { max = 0, ttl, ttlResolution = 1, ttlAutopurge, updateAgeOnGet, updateAgeOnHas, allowStale, dispose, disposeAfter, noDisposeOnSet, noUpdateTTL, maxSize = 0, maxEntrySize = 0, sizeCalculation, fetchMethod, memoMethod, noDeleteOnFetchRejection, noDeleteOnStaleGet, allowStaleOnFetchRejection, allowStaleOnFetchAbort, ignoreFetchAbort } = options;
    if (max !== 0 && !isPosInt(max))
      throw new TypeError("max option must be a nonnegative integer");
    const UintArray = max ? getUintArray(max) : Array;
    if (!UintArray)
      throw new Error("invalid max value: " + max);
    if (this.#max = max, this.#maxSize = maxSize, this.maxEntrySize = maxEntrySize || this.#maxSize, this.sizeCalculation = sizeCalculation, this.sizeCalculation) {
      if (!this.#maxSize && !this.maxEntrySize)
        throw new TypeError("cannot set sizeCalculation without setting maxSize or maxEntrySize");
      if (typeof this.sizeCalculation != "function")
        throw new TypeError("sizeCalculation set to non-function");
    }
    if (memoMethod !== void 0 && typeof memoMethod != "function")
      throw new TypeError("memoMethod must be a function if defined");
    if (this.#memoMethod = memoMethod, fetchMethod !== void 0 && typeof fetchMethod != "function")
      throw new TypeError("fetchMethod must be a function if specified");
    if (this.#fetchMethod = fetchMethod, this.#hasFetchMethod = !!fetchMethod, this.#keyMap = /* @__PURE__ */ new Map(), this.#keyList = new Array(max).fill(void 0), this.#valList = new Array(max).fill(void 0), this.#next = new UintArray(max), this.#prev = new UintArray(max), this.#head = 0, this.#tail = 0, this.#free = Stack.create(max), this.#size = 0, this.#calculatedSize = 0, typeof dispose == "function" && (this.#dispose = dispose), typeof disposeAfter == "function" ? (this.#disposeAfter = disposeAfter, this.#disposed = []) : (this.#disposeAfter = void 0, this.#disposed = void 0), this.#hasDispose = !!this.#dispose, this.#hasDisposeAfter = !!this.#disposeAfter, this.noDisposeOnSet = !!noDisposeOnSet, this.noUpdateTTL = !!noUpdateTTL, this.noDeleteOnFetchRejection = !!noDeleteOnFetchRejection, this.allowStaleOnFetchRejection = !!allowStaleOnFetchRejection, this.allowStaleOnFetchAbort = !!allowStaleOnFetchAbort, this.ignoreFetchAbort = !!ignoreFetchAbort, this.maxEntrySize !== 0) {
      if (this.#maxSize !== 0 && !isPosInt(this.#maxSize))
        throw new TypeError("maxSize must be a positive integer if specified");
      if (!isPosInt(this.maxEntrySize))
        throw new TypeError("maxEntrySize must be a positive integer if specified");
      this.#initializeSizeTracking();
    }
    if (this.allowStale = !!allowStale, this.noDeleteOnStaleGet = !!noDeleteOnStaleGet, this.updateAgeOnGet = !!updateAgeOnGet, this.updateAgeOnHas = !!updateAgeOnHas, this.ttlResolution = isPosInt(ttlResolution) || ttlResolution === 0 ? ttlResolution : 1, this.ttlAutopurge = !!ttlAutopurge, this.ttl = ttl || 0, this.ttl) {
      if (!isPosInt(this.ttl))
        throw new TypeError("ttl must be a positive integer if specified");
      this.#initializeTTLTracking();
    }
    if (this.#max === 0 && this.ttl === 0 && this.#maxSize === 0)
      throw new TypeError("At least one of max, maxSize, or ttl is required");
    if (!this.ttlAutopurge && !this.#max && !this.#maxSize) {
      const code = "LRU_CACHE_UNBOUNDED";
      shouldWarn(code) && (warned.add(code), emitWarning("TTL caching without ttlAutopurge, max, or maxSize can result in unbounded memory consumption.", "UnboundedCacheWarning", code, LRUCache));
    }
  }
  /**
   * Return the number of ms left in the item's TTL. If item is not in cache,
   * returns `0`. Returns `Infinity` if item is in cache without a defined TTL.
   */
  getRemainingTTL(key) {
    return this.#keyMap.has(key) ? 1 / 0 : 0;
  }
  #initializeTTLTracking() {
    const ttls = new ZeroArray(this.#max), starts = new ZeroArray(this.#max);
    this.#ttls = ttls, this.#starts = starts, this.#setItemTTL = (index, ttl, start = perf.now()) => {
      if (starts[index] = ttl !== 0 ? start : 0, ttls[index] = ttl, ttl !== 0 && this.ttlAutopurge) {
        const t = setTimeout(() => {
          this.#isStale(index) && this.#delete(this.#keyList[index], "expire");
        }, ttl + 1);
        t.unref && t.unref();
      }
    }, this.#updateItemAge = (index) => {
      starts[index] = ttls[index] !== 0 ? perf.now() : 0;
    }, this.#statusTTL = (status, index) => {
      if (ttls[index]) {
        const ttl = ttls[index], start = starts[index];
        if (!ttl || !start)
          return;
        status.ttl = ttl, status.start = start, status.now = cachedNow || getNow();
        const age = status.now - start;
        status.remainingTTL = ttl - age;
      }
    };
    let cachedNow = 0;
    const getNow = () => {
      const n = perf.now();
      if (this.ttlResolution > 0) {
        cachedNow = n;
        const t = setTimeout(() => cachedNow = 0, this.ttlResolution);
        t.unref && t.unref();
      }
      return n;
    };
    this.getRemainingTTL = (key) => {
      const index = this.#keyMap.get(key);
      if (index === void 0)
        return 0;
      const ttl = ttls[index], start = starts[index];
      if (!ttl || !start)
        return 1 / 0;
      const age = (cachedNow || getNow()) - start;
      return ttl - age;
    }, this.#isStale = (index) => {
      const s2 = starts[index], t = ttls[index];
      return !!t && !!s2 && (cachedNow || getNow()) - s2 > t;
    };
  }
  // conditionally set private methods related to TTL
  #updateItemAge = () => {
  };
  #statusTTL = () => {
  };
  #setItemTTL = () => {
  };
  /* c8 ignore stop */
  #isStale = () => !1;
  #initializeSizeTracking() {
    const sizes = new ZeroArray(this.#max);
    this.#calculatedSize = 0, this.#sizes = sizes, this.#removeItemSize = (index) => {
      this.#calculatedSize -= sizes[index], sizes[index] = 0;
    }, this.#requireSize = (k, v, size, sizeCalculation) => {
      if (this.#isBackgroundFetch(v))
        return 0;
      if (!isPosInt(size))
        if (sizeCalculation) {
          if (typeof sizeCalculation != "function")
            throw new TypeError("sizeCalculation must be a function");
          if (size = sizeCalculation(v, k), !isPosInt(size))
            throw new TypeError("sizeCalculation return invalid (expect positive integer)");
        } else
          throw new TypeError("invalid size value (must be positive integer). When maxSize or maxEntrySize is used, sizeCalculation or size must be set.");
      return size;
    }, this.#addItemSize = (index, size, status) => {
      if (sizes[index] = size, this.#maxSize) {
        const maxSize = this.#maxSize - sizes[index];
        for (; this.#calculatedSize > maxSize; )
          this.#evict(!0);
      }
      this.#calculatedSize += sizes[index], status && (status.entrySize = size, status.totalCalculatedSize = this.#calculatedSize);
    };
  }
  #removeItemSize = (_i) => {
  };
  #addItemSize = (_i, _s, _st) => {
  };
  #requireSize = (_k, _v, size, sizeCalculation) => {
    if (size || sizeCalculation)
      throw new TypeError("cannot set size without setting maxSize or maxEntrySize on cache");
    return 0;
  };
  *#indexes({ allowStale = this.allowStale } = {}) {
    if (this.#size)
      for (let i = this.#tail; !(!this.#isValidIndex(i) || ((allowStale || !this.#isStale(i)) && (yield i), i === this.#head)); )
        i = this.#prev[i];
  }
  *#rindexes({ allowStale = this.allowStale } = {}) {
    if (this.#size)
      for (let i = this.#head; !(!this.#isValidIndex(i) || ((allowStale || !this.#isStale(i)) && (yield i), i === this.#tail)); )
        i = this.#next[i];
  }
  #isValidIndex(index) {
    return index !== void 0 && this.#keyMap.get(this.#keyList[index]) === index;
  }
  /**
   * Return a generator yielding `[key, value]` pairs,
   * in order from most recently used to least recently used.
   */
  *entries() {
    for (const i of this.#indexes())
      this.#valList[i] !== void 0 && this.#keyList[i] !== void 0 && !this.#isBackgroundFetch(this.#valList[i]) && (yield [this.#keyList[i], this.#valList[i]]);
  }
  /**
   * Inverse order version of {@link LRUCache.entries}
   *
   * Return a generator yielding `[key, value]` pairs,
   * in order from least recently used to most recently used.
   */
  *rentries() {
    for (const i of this.#rindexes())
      this.#valList[i] !== void 0 && this.#keyList[i] !== void 0 && !this.#isBackgroundFetch(this.#valList[i]) && (yield [this.#keyList[i], this.#valList[i]]);
  }
  /**
   * Return a generator yielding the keys in the cache,
   * in order from most recently used to least recently used.
   */
  *keys() {
    for (const i of this.#indexes()) {
      const k = this.#keyList[i];
      k !== void 0 && !this.#isBackgroundFetch(this.#valList[i]) && (yield k);
    }
  }
  /**
   * Inverse order version of {@link LRUCache.keys}
   *
   * Return a generator yielding the keys in the cache,
   * in order from least recently used to most recently used.
   */
  *rkeys() {
    for (const i of this.#rindexes()) {
      const k = this.#keyList[i];
      k !== void 0 && !this.#isBackgroundFetch(this.#valList[i]) && (yield k);
    }
  }
  /**
   * Return a generator yielding the values in the cache,
   * in order from most recently used to least recently used.
   */
  *values() {
    for (const i of this.#indexes())
      this.#valList[i] !== void 0 && !this.#isBackgroundFetch(this.#valList[i]) && (yield this.#valList[i]);
  }
  /**
   * Inverse order version of {@link LRUCache.values}
   *
   * Return a generator yielding the values in the cache,
   * in order from least recently used to most recently used.
   */
  *rvalues() {
    for (const i of this.#rindexes())
      this.#valList[i] !== void 0 && !this.#isBackgroundFetch(this.#valList[i]) && (yield this.#valList[i]);
  }
  /**
   * Iterating over the cache itself yields the same results as
   * {@link LRUCache.entries}
   */
  [Symbol.iterator]() {
    return this.entries();
  }
  /**
   * A String value that is used in the creation of the default string
   * description of an object. Called by the built-in method
   * `Object.prototype.toString`.
   */
  [Symbol.toStringTag] = "LRUCache";
  /**
   * Find a value for which the supplied fn method returns a truthy value,
   * similar to `Array.find()`. fn is called as `fn(value, key, cache)`.
   */
  find(fn, getOptions = {}) {
    for (const i of this.#indexes()) {
      const v = this.#valList[i], value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;
      if (value !== void 0 && fn(value, this.#keyList[i], this))
        return this.get(this.#keyList[i], getOptions);
    }
  }
  /**
   * Call the supplied function on each item in the cache, in order from most
   * recently used to least recently used.
   *
   * `fn` is called as `fn(value, key, cache)`.
   *
   * If `thisp` is provided, function will be called in the `this`-context of
   * the provided object, or the cache if no `thisp` object is provided.
   *
   * Does not update age or recenty of use, or iterate over stale values.
   */
  forEach(fn, thisp = this) {
    for (const i of this.#indexes()) {
      const v = this.#valList[i], value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;
      value !== void 0 && fn.call(thisp, value, this.#keyList[i], this);
    }
  }
  /**
   * The same as {@link LRUCache.forEach} but items are iterated over in
   * reverse order.  (ie, less recently used items are iterated over first.)
   */
  rforEach(fn, thisp = this) {
    for (const i of this.#rindexes()) {
      const v = this.#valList[i], value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;
      value !== void 0 && fn.call(thisp, value, this.#keyList[i], this);
    }
  }
  /**
   * Delete any stale entries. Returns true if anything was removed,
   * false otherwise.
   */
  purgeStale() {
    let deleted = !1;
    for (const i of this.#rindexes({ allowStale: !0 }))
      this.#isStale(i) && (this.#delete(this.#keyList[i], "expire"), deleted = !0);
    return deleted;
  }
  /**
   * Get the extended info about a given entry, to get its value, size, and
   * TTL info simultaneously. Returns `undefined` if the key is not present.
   *
   * Unlike {@link LRUCache#dump}, which is designed to be portable and survive
   * serialization, the `start` value is always the current timestamp, and the
   * `ttl` is a calculated remaining time to live (negative if expired).
   *
   * Always returns stale values, if their info is found in the cache, so be
   * sure to check for expirations (ie, a negative {@link LRUCache.Entry#ttl})
   * if relevant.
   */
  info(key) {
    const i = this.#keyMap.get(key);
    if (i === void 0)
      return;
    const v = this.#valList[i], value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;
    if (value === void 0)
      return;
    const entry = { value };
    if (this.#ttls && this.#starts) {
      const ttl = this.#ttls[i], start = this.#starts[i];
      if (ttl && start) {
        const remain = ttl - (perf.now() - start);
        entry.ttl = remain, entry.start = Date.now();
      }
    }
    return this.#sizes && (entry.size = this.#sizes[i]), entry;
  }
  /**
   * Return an array of [key, {@link LRUCache.Entry}] tuples which can be
   * passed to {@link LRLUCache#load}.
   *
   * The `start` fields are calculated relative to a portable `Date.now()`
   * timestamp, even if `performance.now()` is available.
   *
   * Stale entries are always included in the `dump`, even if
   * {@link LRUCache.OptionsBase.allowStale} is false.
   *
   * Note: this returns an actual array, not a generator, so it can be more
   * easily passed around.
   */
  dump() {
    const arr = [];
    for (const i of this.#indexes({ allowStale: !0 })) {
      const key = this.#keyList[i], v = this.#valList[i], value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;
      if (value === void 0 || key === void 0)
        continue;
      const entry = { value };
      if (this.#ttls && this.#starts) {
        entry.ttl = this.#ttls[i];
        const age = perf.now() - this.#starts[i];
        entry.start = Math.floor(Date.now() - age);
      }
      this.#sizes && (entry.size = this.#sizes[i]), arr.unshift([key, entry]);
    }
    return arr;
  }
  /**
   * Reset the cache and load in the items in entries in the order listed.
   *
   * The shape of the resulting cache may be different if the same options are
   * not used in both caches.
   *
   * The `start` fields are assumed to be calculated relative to a portable
   * `Date.now()` timestamp, even if `performance.now()` is available.
   */
  load(arr) {
    this.clear();
    for (const [key, entry] of arr) {
      if (entry.start) {
        const age = Date.now() - entry.start;
        entry.start = perf.now() - age;
      }
      this.set(key, entry.value, entry);
    }
  }
  /**
   * Add a value to the cache.
   *
   * Note: if `undefined` is specified as a value, this is an alias for
   * {@link LRUCache#delete}
   *
   * Fields on the {@link LRUCache.SetOptions} options param will override
   * their corresponding values in the constructor options for the scope
   * of this single `set()` operation.
   *
   * If `start` is provided, then that will set the effective start
   * time for the TTL calculation. Note that this must be a previous
   * value of `performance.now()` if supported, or a previous value of
   * `Date.now()` if not.
   *
   * Options object may also include `size`, which will prevent
   * calling the `sizeCalculation` function and just use the specified
   * number if it is a positive integer, and `noDisposeOnSet` which
   * will prevent calling a `dispose` function in the case of
   * overwrites.
   *
   * If the `size` (or return value of `sizeCalculation`) for a given
   * entry is greater than `maxEntrySize`, then the item will not be
   * added to the cache.
   *
   * Will update the recency of the entry.
   *
   * If the value is `undefined`, then this is an alias for
   * `cache.delete(key)`. `undefined` is never stored in the cache.
   */
  set(k, v, setOptions = {}) {
    if (v === void 0)
      return this.delete(k), this;
    const { ttl = this.ttl, start, noDisposeOnSet = this.noDisposeOnSet, sizeCalculation = this.sizeCalculation, status } = setOptions;
    let { noUpdateTTL = this.noUpdateTTL } = setOptions;
    const size = this.#requireSize(k, v, setOptions.size || 0, sizeCalculation);
    if (this.maxEntrySize && size > this.maxEntrySize)
      return status && (status.set = "miss", status.maxEntrySizeExceeded = !0), this.#delete(k, "set"), this;
    let index = this.#size === 0 ? void 0 : this.#keyMap.get(k);
    if (index === void 0)
      index = this.#size === 0 ? this.#tail : this.#free.length !== 0 ? this.#free.pop() : this.#size === this.#max ? this.#evict(!1) : this.#size, this.#keyList[index] = k, this.#valList[index] = v, this.#keyMap.set(k, index), this.#next[this.#tail] = index, this.#prev[index] = this.#tail, this.#tail = index, this.#size++, this.#addItemSize(index, size, status), status && (status.set = "add"), noUpdateTTL = !1;
    else {
      this.#moveToTail(index);
      const oldVal = this.#valList[index];
      if (v !== oldVal) {
        if (this.#hasFetchMethod && this.#isBackgroundFetch(oldVal)) {
          oldVal.__abortController.abort(new Error("replaced"));
          const { __staleWhileFetching: s2 } = oldVal;
          s2 !== void 0 && !noDisposeOnSet && (this.#hasDispose && this.#dispose?.(s2, k, "set"), this.#hasDisposeAfter && this.#disposed?.push([s2, k, "set"]));
        } else noDisposeOnSet || (this.#hasDispose && this.#dispose?.(oldVal, k, "set"), this.#hasDisposeAfter && this.#disposed?.push([oldVal, k, "set"]));
        if (this.#removeItemSize(index), this.#addItemSize(index, size, status), this.#valList[index] = v, status) {
          status.set = "replace";
          const oldValue = oldVal && this.#isBackgroundFetch(oldVal) ? oldVal.__staleWhileFetching : oldVal;
          oldValue !== void 0 && (status.oldValue = oldValue);
        }
      } else status && (status.set = "update");
    }
    if (ttl !== 0 && !this.#ttls && this.#initializeTTLTracking(), this.#ttls && (noUpdateTTL || this.#setItemTTL(index, ttl, start), status && this.#statusTTL(status, index)), !noDisposeOnSet && this.#hasDisposeAfter && this.#disposed) {
      const dt = this.#disposed;
      let task;
      for (; task = dt?.shift(); )
        this.#disposeAfter?.(...task);
    }
    return this;
  }
  /**
   * Evict the least recently used item, returning its value or
   * `undefined` if cache is empty.
   */
  pop() {
    try {
      for (; this.#size; ) {
        const val = this.#valList[this.#head];
        if (this.#evict(!0), this.#isBackgroundFetch(val)) {
          if (val.__staleWhileFetching)
            return val.__staleWhileFetching;
        } else if (val !== void 0)
          return val;
      }
    } finally {
      if (this.#hasDisposeAfter && this.#disposed) {
        const dt = this.#disposed;
        let task;
        for (; task = dt?.shift(); )
          this.#disposeAfter?.(...task);
      }
    }
  }
  #evict(free) {
    const head = this.#head, k = this.#keyList[head], v = this.#valList[head];
    return this.#hasFetchMethod && this.#isBackgroundFetch(v) ? v.__abortController.abort(new Error("evicted")) : (this.#hasDispose || this.#hasDisposeAfter) && (this.#hasDispose && this.#dispose?.(v, k, "evict"), this.#hasDisposeAfter && this.#disposed?.push([v, k, "evict"])), this.#removeItemSize(head), free && (this.#keyList[head] = void 0, this.#valList[head] = void 0, this.#free.push(head)), this.#size === 1 ? (this.#head = this.#tail = 0, this.#free.length = 0) : this.#head = this.#next[head], this.#keyMap.delete(k), this.#size--, head;
  }
  /**
   * Check if a key is in the cache, without updating the recency of use.
   * Will return false if the item is stale, even though it is technically
   * in the cache.
   *
   * Check if a key is in the cache, without updating the recency of
   * use. Age is updated if {@link LRUCache.OptionsBase.updateAgeOnHas} is set
   * to `true` in either the options or the constructor.
   *
   * Will return `false` if the item is stale, even though it is technically in
   * the cache. The difference can be determined (if it matters) by using a
   * `status` argument, and inspecting the `has` field.
   *
   * Will not update item age unless
   * {@link LRUCache.OptionsBase.updateAgeOnHas} is set.
   */
  has(k, hasOptions = {}) {
    const { updateAgeOnHas = this.updateAgeOnHas, status } = hasOptions, index = this.#keyMap.get(k);
    if (index !== void 0) {
      const v = this.#valList[index];
      if (this.#isBackgroundFetch(v) && v.__staleWhileFetching === void 0)
        return !1;
      if (this.#isStale(index))
        status && (status.has = "stale", this.#statusTTL(status, index));
      else return updateAgeOnHas && this.#updateItemAge(index), status && (status.has = "hit", this.#statusTTL(status, index)), !0;
    } else status && (status.has = "miss");
    return !1;
  }
  /**
   * Like {@link LRUCache#get} but doesn't update recency or delete stale
   * items.
   *
   * Returns `undefined` if the item is stale, unless
   * {@link LRUCache.OptionsBase.allowStale} is set.
   */
  peek(k, peekOptions = {}) {
    const { allowStale = this.allowStale } = peekOptions, index = this.#keyMap.get(k);
    if (index === void 0 || !allowStale && this.#isStale(index))
      return;
    const v = this.#valList[index];
    return this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;
  }
  #backgroundFetch(k, index, options, context) {
    const v = index === void 0 ? void 0 : this.#valList[index];
    if (this.#isBackgroundFetch(v))
      return v;
    const ac = new AC(), { signal } = options;
    signal?.addEventListener("abort", () => ac.abort(signal.reason), {
      signal: ac.signal
    });
    const fetchOpts = {
      signal: ac.signal,
      options,
      context
    }, cb = (v2, updateCache = !1) => {
      const { aborted } = ac.signal, ignoreAbort = options.ignoreFetchAbort && v2 !== void 0;
      if (options.status && (aborted && !updateCache ? (options.status.fetchAborted = !0, options.status.fetchError = ac.signal.reason, ignoreAbort && (options.status.fetchAbortIgnored = !0)) : options.status.fetchResolved = !0), aborted && !ignoreAbort && !updateCache)
        return fetchFail(ac.signal.reason);
      const bf2 = p;
      return this.#valList[index] === p && (v2 === void 0 ? bf2.__staleWhileFetching ? this.#valList[index] = bf2.__staleWhileFetching : this.#delete(k, "fetch") : (options.status && (options.status.fetchUpdated = !0), this.set(k, v2, fetchOpts.options))), v2;
    }, eb = (er) => (options.status && (options.status.fetchRejected = !0, options.status.fetchError = er), fetchFail(er)), fetchFail = (er) => {
      const { aborted } = ac.signal, allowStaleAborted = aborted && options.allowStaleOnFetchAbort, allowStale = allowStaleAborted || options.allowStaleOnFetchRejection, noDelete = allowStale || options.noDeleteOnFetchRejection, bf2 = p;
      if (this.#valList[index] === p && (!noDelete || bf2.__staleWhileFetching === void 0 ? this.#delete(k, "fetch") : allowStaleAborted || (this.#valList[index] = bf2.__staleWhileFetching)), allowStale)
        return options.status && bf2.__staleWhileFetching !== void 0 && (options.status.returnedStale = !0), bf2.__staleWhileFetching;
      if (bf2.__returned === bf2)
        throw er;
    }, pcall = (res, rej) => {
      const fmp = this.#fetchMethod?.(k, v, fetchOpts);
      fmp && fmp instanceof Promise && fmp.then((v2) => res(v2 === void 0 ? void 0 : v2), rej), ac.signal.addEventListener("abort", () => {
        (!options.ignoreFetchAbort || options.allowStaleOnFetchAbort) && (res(void 0), options.allowStaleOnFetchAbort && (res = (v2) => cb(v2, !0)));
      });
    };
    options.status && (options.status.fetchDispatched = !0);
    const p = new Promise(pcall).then(cb, eb), bf = Object.assign(p, {
      __abortController: ac,
      __staleWhileFetching: v,
      __returned: void 0
    });
    return index === void 0 ? (this.set(k, bf, { ...fetchOpts.options, status: void 0 }), index = this.#keyMap.get(k)) : this.#valList[index] = bf, bf;
  }
  #isBackgroundFetch(p) {
    if (!this.#hasFetchMethod)
      return !1;
    const b = p;
    return !!b && b instanceof Promise && b.hasOwnProperty("__staleWhileFetching") && b.__abortController instanceof AC;
  }
  async fetch(k, fetchOptions = {}) {
    const {
      // get options
      allowStale = this.allowStale,
      updateAgeOnGet = this.updateAgeOnGet,
      noDeleteOnStaleGet = this.noDeleteOnStaleGet,
      // set options
      ttl = this.ttl,
      noDisposeOnSet = this.noDisposeOnSet,
      size = 0,
      sizeCalculation = this.sizeCalculation,
      noUpdateTTL = this.noUpdateTTL,
      // fetch exclusive options
      noDeleteOnFetchRejection = this.noDeleteOnFetchRejection,
      allowStaleOnFetchRejection = this.allowStaleOnFetchRejection,
      ignoreFetchAbort = this.ignoreFetchAbort,
      allowStaleOnFetchAbort = this.allowStaleOnFetchAbort,
      context,
      forceRefresh = !1,
      status,
      signal
    } = fetchOptions;
    if (!this.#hasFetchMethod)
      return status && (status.fetch = "get"), this.get(k, {
        allowStale,
        updateAgeOnGet,
        noDeleteOnStaleGet,
        status
      });
    const options = {
      allowStale,
      updateAgeOnGet,
      noDeleteOnStaleGet,
      ttl,
      noDisposeOnSet,
      size,
      sizeCalculation,
      noUpdateTTL,
      noDeleteOnFetchRejection,
      allowStaleOnFetchRejection,
      allowStaleOnFetchAbort,
      ignoreFetchAbort,
      status,
      signal
    };
    let index = this.#keyMap.get(k);
    if (index === void 0) {
      status && (status.fetch = "miss");
      const p = this.#backgroundFetch(k, index, options, context);
      return p.__returned = p;
    } else {
      const v = this.#valList[index];
      if (this.#isBackgroundFetch(v)) {
        const stale = allowStale && v.__staleWhileFetching !== void 0;
        return status && (status.fetch = "inflight", stale && (status.returnedStale = !0)), stale ? v.__staleWhileFetching : v.__returned = v;
      }
      const isStale = this.#isStale(index);
      if (!forceRefresh && !isStale)
        return status && (status.fetch = "hit"), this.#moveToTail(index), updateAgeOnGet && this.#updateItemAge(index), status && this.#statusTTL(status, index), v;
      const p = this.#backgroundFetch(k, index, options, context), staleVal = p.__staleWhileFetching !== void 0 && allowStale;
      return status && (status.fetch = isStale ? "stale" : "refresh", staleVal && isStale && (status.returnedStale = !0)), staleVal ? p.__staleWhileFetching : p.__returned = p;
    }
  }
  async forceFetch(k, fetchOptions = {}) {
    const v = await this.fetch(k, fetchOptions);
    if (v === void 0)
      throw new Error("fetch() returned undefined");
    return v;
  }
  memo(k, memoOptions = {}) {
    const memoMethod = this.#memoMethod;
    if (!memoMethod)
      throw new Error("no memoMethod provided to constructor");
    const { context, forceRefresh, ...options } = memoOptions, v = this.get(k, options);
    if (!forceRefresh && v !== void 0)
      return v;
    const vv = memoMethod(k, v, {
      options,
      context
    });
    return this.set(k, vv, options), vv;
  }
  /**
   * Return a value from the cache. Will update the recency of the cache
   * entry found.
   *
   * If the key is not found, get() will return `undefined`.
   */
  get(k, getOptions = {}) {
    const { allowStale = this.allowStale, updateAgeOnGet = this.updateAgeOnGet, noDeleteOnStaleGet = this.noDeleteOnStaleGet, status } = getOptions, index = this.#keyMap.get(k);
    if (index !== void 0) {
      const value = this.#valList[index], fetching = this.#isBackgroundFetch(value);
      return status && this.#statusTTL(status, index), this.#isStale(index) ? (status && (status.get = "stale"), fetching ? (status && allowStale && value.__staleWhileFetching !== void 0 && (status.returnedStale = !0), allowStale ? value.__staleWhileFetching : void 0) : (noDeleteOnStaleGet || this.#delete(k, "expire"), status && allowStale && (status.returnedStale = !0), allowStale ? value : void 0)) : (status && (status.get = "hit"), fetching ? value.__staleWhileFetching : (this.#moveToTail(index), updateAgeOnGet && this.#updateItemAge(index), value));
    } else status && (status.get = "miss");
  }
  #connect(p, n) {
    this.#prev[n] = p, this.#next[p] = n;
  }
  #moveToTail(index) {
    index !== this.#tail && (index === this.#head ? this.#head = this.#next[index] : this.#connect(this.#prev[index], this.#next[index]), this.#connect(this.#tail, index), this.#tail = index);
  }
  /**
   * Deletes a key out of the cache.
   *
   * Returns true if the key was deleted, false otherwise.
   */
  delete(k) {
    return this.#delete(k, "delete");
  }
  #delete(k, reason) {
    let deleted = !1;
    if (this.#size !== 0) {
      const index = this.#keyMap.get(k);
      if (index !== void 0)
        if (deleted = !0, this.#size === 1)
          this.#clear(reason);
        else {
          this.#removeItemSize(index);
          const v = this.#valList[index];
          if (this.#isBackgroundFetch(v) ? v.__abortController.abort(new Error("deleted")) : (this.#hasDispose || this.#hasDisposeAfter) && (this.#hasDispose && this.#dispose?.(v, k, reason), this.#hasDisposeAfter && this.#disposed?.push([v, k, reason])), this.#keyMap.delete(k), this.#keyList[index] = void 0, this.#valList[index] = void 0, index === this.#tail)
            this.#tail = this.#prev[index];
          else if (index === this.#head)
            this.#head = this.#next[index];
          else {
            const pi = this.#prev[index];
            this.#next[pi] = this.#next[index];
            const ni = this.#next[index];
            this.#prev[ni] = this.#prev[index];
          }
          this.#size--, this.#free.push(index);
        }
    }
    if (this.#hasDisposeAfter && this.#disposed?.length) {
      const dt = this.#disposed;
      let task;
      for (; task = dt?.shift(); )
        this.#disposeAfter?.(...task);
    }
    return deleted;
  }
  /**
   * Clear the cache entirely, throwing away all values.
   */
  clear() {
    return this.#clear("delete");
  }
  #clear(reason) {
    for (const index of this.#rindexes({ allowStale: !0 })) {
      const v = this.#valList[index];
      if (this.#isBackgroundFetch(v))
        v.__abortController.abort(new Error("deleted"));
      else {
        const k = this.#keyList[index];
        this.#hasDispose && this.#dispose?.(v, k, reason), this.#hasDisposeAfter && this.#disposed?.push([v, k, reason]);
      }
    }
    if (this.#keyMap.clear(), this.#valList.fill(void 0), this.#keyList.fill(void 0), this.#ttls && this.#starts && (this.#ttls.fill(0), this.#starts.fill(0)), this.#sizes && this.#sizes.fill(0), this.#head = 0, this.#tail = 0, this.#free.length = 0, this.#calculatedSize = 0, this.#size = 0, this.#hasDisposeAfter && this.#disposed) {
      const dt = this.#disposed;
      let task;
      for (; task = dt?.shift(); )
        this.#disposeAfter?.(...task);
    }
  }
}
function usePerspective(initialPerspective) {
  const [presentationPerspective, setPresentationPerspective] = useState(null);
  return useEffect(() => {
    const comlink = createNode(
      {
        name: "loaders",
        connectTo: "presentation"
      },
      createNodeMachine().provide({
        actors: createCompatibilityActors()
      })
    );
    comlink.on("loader/perspective", (data) => {
      data.perspective !== "raw" && setPresentationPerspective(data.perspective);
    });
    const stop = comlink.start();
    return () => stop();
  }, []), presentationPerspective === null ? initialPerspective : presentationPerspective;
}
const DEFAULT_TAG = "sanity.preview-kit", documentsCache = new LRUCache({
  // Max 500 documents in memory, no big deal if a document is evicted it just means the eventual consistency might take longer
  max: 500
});
function LiveStoreProvider(props) {
  const { children, refreshInterval = 1e4, token } = props;
  if (!props.client)
    throw new Error("Missing a `client` prop with a configured Sanity client instance");
  const perspective = usePerspective(props.perspective || "drafts"), [client] = useState(() => {
    const { requestTagPrefix, resultSourceMap } = props.client.config();
    return props.client.withConfig({
      requestTagPrefix: requestTagPrefix || DEFAULT_TAG,
      resultSourceMap: resultSourceMap === "withKeyArraySelector" ? "withKeyArraySelector" : !0,
      // Set the recommended defaults, this is a convenience to make it easier to share a client config from a server component to the client component
      ...token && {
        token,
        useCdn: !1,
        perspective: "drafts",
        ignoreBrowserTokenWarning: !0
      }
    });
  }), [logger] = useState(() => props.logger);
  useEffect(() => {
    logger && logger.log(
      `[@sanity/preview-kit]: With the current configuration you can expect that: Updates that can be traced using Content Source Maps will be applied in real-time. Other updates will be applied every ${refreshInterval}ms.`
    );
  }, [logger, refreshInterval]);
  const [subscriptions, setSubscriptions] = useState([]), [snapshots] = useState(() => /* @__PURE__ */ new Map()), hooks = useHooks(setSubscriptions), [context] = useState(() => function(initialSnapshot, query, params) {
    const key = getQueryCacheKey(query, params);
    return snapshots.has(key) || snapshots.set(key, {
      result: initialSnapshot,
      resultSourceMap: {}
    }), { subscribe: (onStoreChange) => {
      const unsubscribe = hooks.subscribe(key, query, params, onStoreChange);
      return () => unsubscribe();
    }, getSnapshot: () => snapshots.get(key)?.result };
  }), [turboIds, setTurboIds] = useState([]), [docsInUse] = useState(() => /* @__PURE__ */ new Map()), turboIdsFromSourceMap = useCallback(
    (contentSourceMap) => {
      const nextTurboIds = /* @__PURE__ */ new Set();
      if (docsInUse.clear(), contentSourceMap.documents?.length)
        for (const document of contentSourceMap.documents)
          nextTurboIds.add(document._id), docsInUse.set(document._id, document);
      startTransition(
        () => setTurboIds((prevTurboIds) => {
          const mergedTurboIds = Array.from(/* @__PURE__ */ new Set([...prevTurboIds, ...nextTurboIds]));
          return JSON.stringify(mergedTurboIds.sort()) === JSON.stringify(prevTurboIds.sort()) ? prevTurboIds : mergedTurboIds;
        })
      );
    },
    [docsInUse]
  );
  return /* @__PURE__ */ jsxs(defineStoreContext.Provider, { value: context, children: [
    children,
    /* @__PURE__ */ jsx(
      Turbo,
      {
        cache: hooks.cache,
        client,
        setTurboIds,
        snapshots,
        turboIds,
        docsInUse,
        perspective
      }
    ),
    subscriptions.map((key) => {
      if (!hooks.cache.has(key)) return null;
      const { query, params, listeners } = hooks.cache.get(key);
      return /* @__PURE__ */ jsx(
        QuerySubscription,
        {
          client,
          listeners,
          params,
          query,
          refreshInterval,
          snapshots,
          turboIdsFromSourceMap,
          perspective
        },
        `${key}-${perspective}`
      );
    })
  ] });
}
LiveStoreProvider.displayName = "LiveStoreProvider";
function QuerySubscription(props) {
  const {
    client,
    refreshInterval,
    query,
    params,
    listeners,
    snapshots,
    turboIdsFromSourceMap,
    perspective
  } = props, { projectId, dataset } = useMemo(() => {
    const { projectId: projectId2, dataset: dataset2 } = client.config();
    return { projectId: projectId2, dataset: dataset2 };
  }, [client]), [error, setError] = useState(null);
  if (error) throw error;
  const [revalidate, startRefresh] = useRevalidate({ refreshInterval }), shouldRefetch = revalidate === "refresh" || revalidate === "inflight";
  return useEffect(() => {
    if (!shouldRefetch)
      return;
    let fulfilled = !1;
    const controller = new AbortController();
    async function effect() {
      const { signal } = controller, { result, resultSourceMap } = await client.fetch(query, params, {
        signal,
        filterResponse: !1,
        perspective
      });
      if (!signal.aborted) {
        snapshots.set(getQueryCacheKey(query, params), {
          result: turboChargeResultIfSourceMap(
            projectId,
            dataset,
            result,
            perspective,
            resultSourceMap
          ),
          resultSourceMap: resultSourceMap ?? {}
        }), resultSourceMap && turboIdsFromSourceMap(resultSourceMap);
        for (const listener of listeners.values())
          listener();
        fulfilled = !0;
      }
    }
    const onFinally = startRefresh();
    return effect().catch((error2) => {
      error2.name !== "AbortError" && setError(error2);
    }).finally(onFinally), () => {
      fulfilled || controller.abort();
    };
  }, [
    client,
    dataset,
    listeners,
    params,
    perspective,
    projectId,
    query,
    shouldRefetch,
    snapshots,
    startRefresh,
    turboIdsFromSourceMap
  ]), null;
}
QuerySubscription.displayName = "QuerySubscription";
function getTurboCacheKey(projectId, dataset, _id) {
  return `${projectId}-${dataset}-${_id}`;
}
function useHooks(setSubscriptions) {
  const [cache] = useState(() => /* @__PURE__ */ new Map()), subscribe = useCallback(
    (key, query, params, listener) => {
      cache.has(key) || (cache.set(key, { query, params, listeners: /* @__PURE__ */ new Set() }), startTransition(
        () => setSubscriptions((prevSubscriptions) => prevSubscriptions.includes(key) ? prevSubscriptions : [...prevSubscriptions, key])
      ));
      const hook = cache.get(key);
      if (!hook || !hook.listeners)
        throw new TypeError("Inconsistent cache for key: " + key);
      const { listeners } = hook;
      return listeners.add(listener), () => {
        listeners.delete(listener), listeners.size === 0 && (cache.delete(key), startTransition(
          () => setSubscriptions((prevSubscriptions) => prevSubscriptions.includes(key) ? prevSubscriptions.filter((sub) => sub !== key) : prevSubscriptions)
        ));
      };
    },
    [cache, setSubscriptions]
  );
  return useMemo(() => ({ cache, subscribe }), [cache, subscribe]);
}
function Turbo(props) {
  const { client, snapshots, cache, turboIds, setTurboIds, docsInUse, perspective } = props, { projectId, dataset } = useMemo(() => {
    const { projectId: projectId2, dataset: dataset2 } = client.config();
    return { projectId: projectId2, dataset: dataset2 };
  }, [client]);
  useEffect(() => {
    const nextTurboIds = /* @__PURE__ */ new Set();
    docsInUse.clear();
    for (const { query, params } of cache.values()) {
      const key = getQueryCacheKey(query, params), snapshot = snapshots.get(key);
      if (snapshot && snapshot.resultSourceMap?.documents?.length)
        for (const document of snapshot.resultSourceMap.documents)
          nextTurboIds.add(document._id), docsInUse.set(document._id, document);
    }
    const nextTurboIdsSnapshot = [...nextTurboIds].sort();
    JSON.stringify(turboIds) !== JSON.stringify(nextTurboIdsSnapshot) && startTransition(() => setTurboIds(nextTurboIdsSnapshot));
  }, [cache, docsInUse, setTurboIds, snapshots, turboIds]);
  const [batch, setBatch] = useState([]);
  useEffect(() => {
    const batchSet = new Set(batch.flat()), nextBatch = /* @__PURE__ */ new Set();
    for (const turboId of turboIds)
      !batchSet.has(turboId) && !documentsCache.has(getTurboCacheKey(projectId, dataset, turboId)) && nextBatch.add(turboId);
    const nextBatchSlice = [...nextBatch].slice(0, 100);
    nextBatchSlice.length !== 0 && startTransition(() => setBatch((prevBatch) => [...prevBatch.slice(-100), nextBatchSlice]));
  }, [batch, dataset, projectId, turboIds]);
  const [lastMutatedDocumentId, setLastMutatedDocumentId] = useState();
  return useEffect(() => {
    const subscription = client.listen(
      "*",
      {},
      {
        events: ["mutation"],
        effectFormat: "mendoza",
        includePreviousRevision: !1,
        includeResult: !1,
        tag: "turbo"
      }
    ).subscribe((update) => {
      if (update.type !== "mutation" || !update.effects?.apply?.length) return;
      const key = getTurboCacheKey(projectId, dataset, update.documentId), cachedDocument = documentsCache.peek(key);
      if (cachedDocument) {
        const patchDoc = { ...cachedDocument };
        delete patchDoc._rev;
        const patchedDocument = applyPatch(patchDoc, update.effects.apply);
        documentsCache.set(key, patchedDocument);
      }
      startTransition(() => setLastMutatedDocumentId(update.documentId));
    });
    return () => subscription.unsubscribe();
  }, [client, dataset, projectId]), useEffect(() => {
    if (!lastMutatedDocumentId || !turboIds.includes(lastMutatedDocumentId)) return;
    const updatedKeys = [];
    for (const [key, snapshot] of snapshots.entries())
      snapshot.resultSourceMap?.documents?.length && (snapshot.result = turboChargeResultIfSourceMap(
        projectId,
        dataset,
        snapshot.result,
        perspective,
        snapshot.resultSourceMap
      ), updatedKeys.push(key));
    for (const updatedKey of updatedKeys) {
      const listeners = cache.get(updatedKey)?.listeners;
      if (listeners)
        for (const listener of listeners)
          listener();
    }
    startTransition(() => setLastMutatedDocumentId(void 0));
  }, [cache, dataset, lastMutatedDocumentId, perspective, projectId, snapshots, turboIds]), /* @__PURE__ */ jsx(Fragment, { children: batch.map((ids) => /* @__PURE__ */ jsx(
    GetDocuments,
    {
      client,
      projectId,
      dataset,
      ids
    },
    JSON.stringify(ids)
  )) });
}
Turbo.displayName = "Turbo";
function GetDocuments(props) {
  const { client, projectId, dataset, ids } = props;
  return useEffect(() => {
    const missingIds = ids.filter(
      (id) => !documentsCache.has(getTurboCacheKey(projectId, dataset, id))
    );
    missingIds.length !== 0 && client.getDocuments(missingIds).then((documents) => {
      for (const doc of documents)
        doc && doc?._id && documentsCache.set(getTurboCacheKey(projectId, dataset, doc._id), doc);
    }, console.error);
  }, [client, dataset, ids, projectId]), null;
}
GetDocuments.displayName = "GetDocuments";
let warnedAboutCrossDatasetReference = !1;
function turboChargeResultIfSourceMap(projectId, dataset, result, perspective, resultSourceMap) {
  return resultSourceMap ? applySourceDocuments(
    result,
    resultSourceMap,
    (sourceDocument) => {
      if (sourceDocument._projectId) {
        warnedAboutCrossDatasetReference || (console.warn(
          "Cross dataset references are not supported yet, ignoring source document",
          sourceDocument
        ), warnedAboutCrossDatasetReference = !0);
        return;
      }
      return documentsCache.get(getTurboCacheKey(projectId, dataset, sourceDocument._id));
    },
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    (changedValue, { previousValue }) => {
      if (typeof changedValue == "string" && typeof previousValue == "string") {
        const { encoded } = _(previousValue), { cleaned } = _(changedValue);
        return `${encoded}${cleaned}`;
      }
      return changedValue;
    },
    perspective
  ) : result;
}
function getQueryCacheKey(query, params) {
  return `${query}-${JSON.stringify(params)}`;
}
export {
  LiveStoreProvider as default
};
//# sourceMappingURL=LiveQueryProvider.js.map
